# Laborat√≥rio de Prompt Injection e Defesa em LLMs

Este reposit√≥rio serve como um laborat√≥rio pr√°tico para o estudo de vulnerabilidades em Grandes Modelos de Linguagem (LLMs). Atrav√©s de um Jupyter Notebook, √© demonstrado de forma clara como ataques de **Prompt Injection** podem ocorrer e, mais importante, √© comprado a efic√°cia de diferentes t√©cnicas de engenharia de prompt para defesa.

O c√≥digo utiliza a plataforma [Ollama](https://ollama.com/) para rodar um modelo open-source localmente, permitindo que qualquer pessoa possa replicar os experimentos de forma segura e gratuita.

## üéØ Cen√°rio do Experimento

O objetivo √© testar a robustez de um assistente de IA para uma cl√≠nica veterin√°ria, que tem a instru√ß√£o de responder **apenas** sobre cachorros e gatos. O ataque consiste em uma s√©rie de 10 prompts maliciosos que tentam for√ßar o assistente a quebrar sua regra principal e responder qual √© a capital do Brasil.

Comparamos a taxa de falha (sucesso do ataque) em quatro implementa√ß√µes de assistentes, cada uma com um n√≠vel de defesa diferente.

## üî¨ Assistentes e T√©cnicas de Defesa

O notebook implementa e compara quatro assistentes:

1.  **`Dummy` (Linha de Base):** Um assistente com um prompt de sistema simples e direto. Representa uma implementa√ß√£o comum e ing√™nua, sem defesas expl√≠citas.

2.  **`Sophisticated` (IA Constitucional & Spotlighting):** Esta defesa implementa duas pr√°ticas recomendadas:
    * **IA Constitucional:** Define um conjunto de regras expl√≠citas e inviol√°veis (`<regras>`).
    * **Spotlighting:** Envolve a entrada do usu√°rio em delimitadores (`<entrada_usuario>`) e instrui o modelo a tratar o conte√∫do como dados brutos, e n√£o como comandos.

3.  **`Dummy with Reminder` (Refor√ßo no Final):** Uma t√©cnica que explora uma caracter√≠stica da arquitetura dos LLMs. Ao repetir a instru√ß√£o de sistema original *ap√≥s* a pergunta do usu√°rio, aproveitamos o **efeito de rec√™ncia**, garantindo que a diretriz principal seja a √∫ltima coisa que o modelo "l√™" antes de responder.

4.  **`Sophisticated with Reminder` (Defesa em Camadas):** A implementa√ß√£o mais robusta, que combina as duas t√©cnicas anteriores. Ela usa a estrutura da "constitui√ß√£o" e, adicionalmente, refor√ßa essa mesma constitui√ß√£o ao final do prompt do usu√°rio.


## ‚öôÔ∏è Pr√©-requisitos

Antes de executar o notebook, garanta que voc√™ tenha o seguinte ambiente configurado:

1.  **Python 3.10+**
2.  **Ollama instalado:** Siga as instru√ß√µes de instala√ß√£o em [ollama.com](https://ollama.com/).
3.  **Modelo Granite-3B baixado:** Ap√≥s instalar o Ollama, execute o seguinte comando no seu terminal para baixar o modelo que usamos nos exemplos:
    ```sh
    ollama pull granite3.3:2b
    ```
    *(Nota: Embora o c√≥digo original use `granite3.3:2b`. Ajuste o nome do modelo no notebook se necess√°rio.)*

## üìä Resultados Esperados

Ao executar o notebook, voc√™ observar√° uma clara progress√£o na efic√°cia das defesas. A taxa de sucesso dos ataques (falhas do assistente) deve diminuir significativamente a cada n√≠vel de defesa implementado, seguindo a ordem:

`Dummy` > `Sophisticated` > `Dummy with Reminder` > `Sophisticated with Reminder`

Isso demonstra que, embora n√£o exista uma solu√ß√£o 100% infal√≠vel, a aplica√ß√£o de m√∫ltiplas camadas de defesa na engenharia do prompt aumenta drasticamente a resili√™ncia do LLM contra manipula√ß√µes.

## üìö Refer√™ncias e Leitura Adicional

As t√©cnicas e vulnerabilidades demonstradas neste reposit√≥rio s√£o baseadas em pesquisas e padr√µes de seguran√ßa estabelecidos pela comunidade de IA.

1.  **[OWASP Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)**: A principal refer√™ncia da ind√∫stria para seguran√ßa em IA. O **Prompt Injection (LLM01)** √© listado como a vulnerabilidade n√∫mero um.
2.  **[Constitutional AI (Anthropic)](https://www.anthropic.com/news/claudes-constitution)**: A abordagem da Anthropic de criar um conjunto de regras expl√≠citas para guiar o comportamento do modelo, que inspirou o assistente `Sophisticated`.
3.  **[AI Engineering - Building Applications with Foundation Models (Chip Huyen)](https://www.oreilly.com/library/view/ai-engineering/9781098163423/)**: Livro que menciona a t√©cnica de refor√ßar instru√ß√µes ao final do prompt para combater o efeito "Lost in the Middle".

Criado com üß† por **Alex Bispo**.
